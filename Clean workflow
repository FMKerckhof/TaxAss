RRR 12-5-15

This workflow assigns taxonomy to a fasta file of otu sequences using both a 
small, custom taxonomy database and a large general database.

Summary of Steps and Commands (all commands entered in terminal window):

-1. background on why we chose this workflow

0. format files (textwrangler or bash)
	depends on your starting file formats
	for Green Genes database as general.taxonomy:
		sed 's/ //g' <general.taxonomy >NoSpaces
		sed 's/$/;/' <NoSpaces >EndLineSemicolons
		mv EndLineSemicolons general.taxonomy
		rm NoSpaces

NOTE: steps 1-14 can be run in a block using the bash script LazyRun.sh.  to source type in the terminal:
	./LazyRun.sh
		
1. make BLAST database file (blast)
	makeblastdb -dbtype nucl -in custom.fasta -input_type fasta -parse_seqids -out custom.db

2. run BLAST (blast)
	blastn -query otus.fasta -task megablast -db custom.db -out otus.custom.blast -outfmt 11 -max_target_seqs 5

3. reformat blast results (blast)
	blast_formatter -archive otus.custom.blast -outfmt "6 qseqid pident length qlen qstart qend" -out otus.custom.blast.table

4. correct BLAST pident (R)
	Rscript calc_full_length_pident.R otus.custom.blast.table otus.custom.blast.table.modified

5. filter BLAST results (R)
	Rscript filter_seqIDs_by_pident.R otus.custom.blast.table.modified ids.above.98 98 TRUE 
	Rscript filter_seqIDs_by_pident.R otus.custom.blast.table.modified ids.below.98 98 FALSE

6. check that BLAST settings are appropriate (R)
	mkdir plots
	RScript plot_blast_hit_stats.R otus.custom.blast.table.modified 98 plots

7. recover sequence IDs left out of blast (python, bash)
	python find_seqIDs_blast_removed.py otus.fasta otus.custom.blast.table.modified ids.missing
	cat ids.below.98 ids.missing > ids.below.98.all
	
8. create fasta files of desired sequence IDs (python)
	python create_fastas_given_seqIDs.py ids.above.98 otus.fasta otus.above.98.fasta
	python create_fastas_given_seqIDs.py ids.below.98.all otus.fasta otus.below.98.fasta

9. assign taxonomy (mothur)
	mothur "#classify.seqs(fasta=otus.above.98.fasta, template=custom.fasta,  taxonomy=custom.taxonomy, method=wang, probs=T, processors=2)"
	mothur "#classify.seqs(fasta=otus.below.98.fasta, template=general.fasta, taxonomy=general.taxonomy, method=wang, probs=T, processors=2)"

10. combine taxonomy files (terminal)
	cat otus.above.98.custom.wang.taxonomy otus.below.98.general.wang.taxonomy > otus.98.taxonomy

11. assign taxonomy with general database only (mothur, bash)
	mothur "#classify.seqs(fasta=otus.fasta, template=general.fasta, taxonomy=general.taxonomy, method=wang, probs=T, processors=2)"
	cat otus.general.wang.taxonomy > otus.general.taxonomy

11.5 OPTIONAL database improvement check, see database improvement workflow step 11.5

12. reformat taxonomy files (bash)
	sed 's/[[:blank:]]/\;/' <otus.98.taxonomy >otus.98.taxonomy.reformatted
	mv otus.98.taxonomy.reformatted otus.98.taxonomy
	sed 's/[[:blank:]]/\;/' <otus.general.taxonomy >otus.general.taxonomy.reformatted
	mv otus.general.taxonomy.reformatted otus.general.taxonomy
	
13. compare taxonomy files (R)
	mkdir conflicts_98
	Rscript find_classification_disagreements.R otus.98.taxonomy otus.general.taxonomy ids.above.98 conflicts_98 98 85 70
	
14. choose appropriate pident cutoff (R)
	Rscript plot_classification_disagreements.R otus.abund plots regular NA conflicts_94 ids.above.94 94 conflicts_96 ids.above.96 96 conflicts_98 ids.above.98 98

15. generate final taxonomy file (R)
	Rscript find_classification_disagreements.R otus.98.taxonomy NA ids.above.98 conflicts_98 98 85 70 final

16. OPTIONAL: plot benefits of using this workflow (R)
	Rscript plot_classification_improvement.R final.taxonomy.pvalues final.general.pvalues total.reads.per.seqID.csv plots
	mothur "#classify.seqs(fasta=otus.fasta, template=custom.fasta, taxonomy=custom.taxonomy, method=wang, probs=T, processors=2)"
	cat otus.custom.wang.taxonomy > otus.custom.taxonomy
	sed 's/[[:blank:]]/\;/' <otus.custom.taxonomy >otus.custom.taxonomy.reformatted
	mv otus.custom.taxonomy.reformatted otus.custom.taxonomy
	mkdir conflicts_forcing
	Rscript find_classification_disagreements.R otus.custom.taxonomy otus.98.85.70.taxonomy ids.above.98 conflicts_forcing NA 85 70 forcing
	Rscript plot_classification_disagreements.R NA plots NA conflicts_forcing otus.custom.85.taxonomy

17. tidy up (bash)
	rm custom.db.* custom.8mer custom.custom* custom.tree* general.8mer general.general* general.tree* *wang* mothur.*.logfile otus.custom.blast* ids* otus.below*.fasta otus.above*.fasta otus.[0-9][0-9].taxonomy otus.[0-9][0-9][0-9].taxonomy otus.general.taxonomy otus.custom.taxonomy custom.general* otus.custom.[0-9]* *pvalues total*
	mkdir scripts ; mv *.py *.R *.sh scripts
	mkdir analysis ; mv conflicts* plots analysis
	mkdir data ; mv otus* data
	mkdir databases ; mv *.taxonomy *.fasta databases
	
Detailed explanations of commands and inputs are below:


__________________________________________________________________________________________

-1. background on why we chose this workflow

Our original taxonomy assignment workflow was straightforward and more simple: 
	everything was classified to 70% using our FW database
	all classifications that weren't "unclassified" at the lineage level were kept
	everything else was re-classified using green genes to 60%

However this workflow was flawed due to a misunderstanding of the classification p values:
	-The 70% bootstrap value refers to the repeatability of the taxonomy assignment,
	NOT to it's accuracy.
	-A classification that is given at 70% confidence means that 70% of the time 
	when you feed that sequence into that database it goes into that group.
	-The classifier sill puts anything you feed into it a classification, 
	even it the true classification is not included in the database.
	-The GG database is huge, if you put something into it that the database doesn't have,
	it will likely put it in random different clusters each time and it will be "unclassified"
	-Our database is small.  If you put something into it that it doesn't have,
	it fill find whatever it's closest to and consistently call it that because there are 
	not as many dissimilar options to spread it between.
		consistently. meaning a high bootstrap value.
	-simple example: if you give our FW database an archaea sequence, 100% of the time
	it will say it is a bacteria- because the database only has bacteria in it.

Consequences of the flaw:
	-we were forcing sequences that do not match well to be called our favorite FW taxa
		-we may have missed other taxa that may be important
		-we may have muddied the relationships of our key taxa by adding in unrelated ones

Possible solutions and why they don't work:
	-Classify in GG first
		-then reclassify the "freshwater" phylums.
		-this is basically what Jason did to solve the problem
		-but phyla are too broad in GG, can't assume everything in phylum is in our database
	-Classify in GG first
		-then reclassify the "freshwater" orders (or some lower level)
		-but GG lacks the resolution to identify those orders,
		we'd miss many sequences b/c GG would call them unclassified
	-Combine the two taxonomy databases and classify all at once
		-if something is present in both databases, it will be split during classification,
		50% going into one, the other 50% into the other, and remain unclassified
	-Classify our sequences with green genes, remove those green genes sequences, and then
	combine the databases and classify all at once
		-the taxonomy databases are highly curated, adding something new in is not that simple.
			-the structure of the two databases may differ at higher taxonomic resolution
			-the green genes classification might not actually be a good match if the freshwater
			sequence just doesn't exist in green genes, so then we'd be removing an unrelated
			sequence that we shouldn't.
				-how can you differentiate if the fw sequence does not exist in gg
				or if the fw sequence exists in gg but is only named to class level.
	-Classify the sequences in the freshwater database with a different method, like BLAST,
	since it's a small database anyway.
		-the taxonomy assignment algorithm takes into consideration phylogeny, which is a
		better classification that by just using sequence similarity.
	
Our solution/this workflow (that we think works):
	-Classify in FW first, but with a cutoff not based on clustering bootstrap values
		-use a BLAST cutoff to identify highly similar sequences to those in
		our freshwater sequence database
		-classify those hightly similar sequences with a classification algorithm and our db
		-classify the remaining sequences with a large database
		

__________________________________________________________________________________________

0. format files (textwrangler or bash)

These are the files you supply as input into the workflow:
	custom.fasta		fasta sequences in your small, specific taxonomy database
	custom.taxonomy		taxonomy names in your small, specific taxonomy database
	general.fasta		fasta sequences in your large, general taxonomy database
	general.taxonomy	taxonomy names in your large, general taxonomy database
	otus.fasta			fasta sequences for each of your OTUs
	otus.abund			relative abundance of each OTU (i.e. the OTU table)

I recommend you move all of these files into a new folder that also contains the workflow scripts, 
and rename them to match the above names so that you can copy and paste commands from this workflow.
Also put the script files in this workflow into that same folder.
Then make that folder your working directory for the entirety of this workflow.

I. General notes on the seqIDs in all files:

OTU seqID's:
			-cannot contain any whitespace
			 BLAST will call some parts the seqID and some parts comments if they're separated.
			 Having BLAST seqIDs that don't match the full >comment line of the fasta file will 
		 	 throw off the python script that creates fasta files for the chosen seqIDs in step 8.
		 	 -must match between the otus.fasta file and the otus.abund file,
			 though consistent ordering is not necessary.


II. Taxonomy Database Files:

	1. .taxonomy files: 
		-must be compatible with mothur, example format:
		
			seqID tab kingdom;phylum;class;order;family;genus;species;
		
		-no whitespace except for the tab between seqID and taxonomy
		-taxonomy level names separated by semicolons
		-must have a semicolon at the end of each line, too!
		
		-If you are using the Green Genes taxonomy database, you can reformat it this way: 

	Full 4 Commands (type in terminal) when general.taxonomy is the green genes taxonomy file:

	sed 's/ //g' <general.taxonomy >NoSpaces
	sed 's/$/;/' <NoSpaces >EndLineSemicolons
	mv EndLineSemicolons general.taxonomy
	rm NoSpaces

			Syntax of commands and what each argument does:
				sed 's/find/replace/ <input >output
					sed		is a "stream editor," a function for editing streams of text in the terminal
					s		tells it you are doing a substitution
							in the first sed command that was simply a typed space
							in the second sed command the $ means 'end of line'
					replace	this is what you are replacing with
							in the first sed command it was left blank, to simply remove spaces
							in the second sed command it is a semicolon
					g		this means "global" find/replace all occurances, not just the first per line
					input	this is the file sed searches through, here it is general.taxonomy (if that is green genes!)
					output	this is the file sed creates (note it must have a different name than input)
	
				mv filename1 filename2
					mv		this is a function to move (aka rename) a file from name1 to name2
							simply keeping the edited file the same name  
				rm filename
					rm		this removes (aka deletes) the file named filename
		

			-If you are using the Silva database... ***add formatting advice***
			*************

	2. .fasta files:
		-these should be in fasta format (note the carrot before the seqID, a new line 
		separateing seqID from sequence, sequence can be one line or multiple lines.)
		
		>seqID
		TACGTAGGGTGCAAGCGTTAATCGGAATTACTGGGCGTAAAG
		>seqID
		TACGTAGGGTGCAAGCGTTAATCGGAATTACTGGGCGTAAAG
		
II. Your OTU files:
		-QC of your OTU sequences should be performed before you start assigning taxonomy.
		 if you start using mothur, and start this workflow right before the first classify.seqs() command
		 if you start using qiime ****where do you start there??**

	1. .fasta file:
		- same format as the taxonomy database fasta files, above.
		
		- if you're using mothur, this file is called:
		stability.trim.contigs.good.unique.good.filter.unique.precluster.pick.fasta
		
		- if you're using qiime, this file is called:
		*****look up qiime***
		
		to format the mothur file:

	2. .abund file:
		- this is the table of relative abundances for each OTU in each sample, 
		 aka your OTU table.
		 
		-format is tab delimited, seqIDs in 1st column, abundances in rest of columns:
			seqID	Abundance	Abundance	Abundance	Abundance
			seqID	Abundance	Abundance	Abundance	Abundance
			seqID	Abundance	Abundance	Abundance	Abundance
		
		
		- If you're using mothur, this file is called:
		***fill this in!!!***
		
		-If you're using qiime, this file is called:
		****check on this***
		
		
__________________________________________________________________________________________

1. make BLAST database file (blast)

Use the command makeblastdb to create a blast database out of the FW taxonomy fasta files.
Need to create a database because:
	1. BLAST will run faster
	2. Having a database is necessary for some of the output formats

Full Command (type in terminal):

makeblastdb -dbtype nucl -in custom.fasta -input_type fasta -parse_seqids -out custom.db

What each argument is:
	-dbtype nucl		a required argument, says the database input file is nucleic acids (nucl)
	-in custom.fasta	specify path of the input file that it makes the database out of.
						this is the path to the small custom taxonomy file you want to use 
						(i.e. the freshwater taxonomy database fasta file)
						note: if the file path has spaces in it, it needs to be ' "/path/double quoted" '
	-input_type fasta	specifies the input file is a fasta file (that's the default value too)
	-parse_seqids		this tells it to include information in the database that will later
						allow you to pull sequences back out of it.  
						This is necessary for using blast_formatter later.
	-out custom.db		specify path of the database files this command creats. BLAST makes 6 files 
						with different extensions, but they all start with this.  BLAST Default is your 
						-in file name with those extensions, but it's less confusing to add .db so you 
						can easily identify what each file is.  

These 6 files are created:
	custom.db.nhr
	custom.db.nog
	custom.db.nsd
	custom.db.nsi
	custom.db.nsq
(but later when you tell BLAST which database file to use you just say custom.db and it figures the rest out)

__________________________________________________________________________________________

2. run BLAST (blast)

Use the command blastn to run a megablast that returns the best hit in the taxonomy database (subject)
for each of your OTU sequences (queries). Megablast is optimized for finding very similar matches with
sequences longer than 30 bp.  This workflow was made for ~100 bp sequences and may need to be re-optimized
for sequences of different lengths.  You check if settings are appropriate in step 6.

Full Command (type in terminal):

blastn -query otus.fasta -task megablast -db custom.db -out otus.custom.blast -outfmt 11 -max_target_seqs 5

What each argument is:						
	-query otus.fasta 		specify path of query file, otus.fasta.  This is the fasta file of your OTU 
							sequences you want classified that you reformatted in step 0.
	-task megablast 		this is already optimized by smart BLAST people for high similarity hits.
							It is also the blastn default task. for more info see 
							http://www.ncbi.nlm.nih.gov/Class/MLACourse/Modules/BLAST/nucleotide_blast.html
	-db custom.db 			the name of the blast database created in step 1(without the additional file extensions)
							This database is made from your subject sequences, the small, custom taxonomy database
	-out otus.custom.blast	specify path of the blast output file (this is the file you're creating). Its format 
							is unreadable by you, but it's the detailed BLAST format that blast_formatter accepts.
							The filename here describes query.subject.blast
	-outfmt 11 				need this format in order to use blast_formatter command
	-max_target_seqs 5		only keep the best 5 hits for each query sequence
							you will compare how good these are to check if BLAST settings are appropriate in step 6
							you can choose more or less target seqs if you want to, it doesn't have a huge impact on speed.

__________________________________________________________________________________________

3. reformat BLAST results (blast)

The blast_formatter function in blast takes the outformat 11 file and reformats it to any other
possible format.  Here we reformat to a custom table format to feed into the R script the pulls out
matching and nonmatching sequence IDs.
However, using blast_formatter you can look at your blast results from the previous step any way you'd like!
Just keep in mind, things like "length" have different definitions in different output formats (yeah. really.), 
so pay careful attention if you try to re-do calculations on your own.

Full Command (type in terminal):

blast_formatter -archive otus.custom.blast -outfmt "6 qseqid pident length qlen qstart qend" -out otus.custom.blast.table

What each argument is:		
	-archive otus.custom.blast 		Specify path to the blast result file you are reformatting.
									This was generated in step 2, it is in the ASN.1 blast file format.
	-outfmt "6 qseqid pident length qlen qstart qend"	
									6 is a tabular format without headers or other info btwn rows of data, 
									the rest specifies what goes in each tab-delimited column:
										1 qseqid: query (OTU) sequence ID
										2 pident: percent identity (# of matches / # "columns" in the sequence)
										3 length: length of alignment
										4 qlen: full length of query sequence
										5 qstart: index of beginning of alignment on query sequence
										6 qend: index of end of alignment on query sequence
	-out otus.custom.blast.table	Specify path to the output file with above formatting.
				
__________________________________________________________________________________________

4. correct BLAST pident (R)

The calc_full_length_pident.R script takes the formatted blast file and calculates a 
"full length" pident value that corrects the pident value for the entire length of the query.
BLAST returns the "highest scoring pair", which is weighted by both similarity and length.
However we are trying to compare the entire OTU sequence, not just a section of it that 
matches really well.  I could not find any command that forces blast use the entire query 
sequence, so this is the workaround. This "full length" pident is a conservative, worst case 
scenario that assumes any edge gaps are mismatches.
Calculation:
	"full length pident" = pident * length / (length - (qend - qstart) + qlen)
This script performs those calculations, and then checks which of the top 5 reported BLAST hits had
the best corrected, full length pident.  It returns a similar, tab delimited output file that 
includes the corrected full length pident and which BLAST hit number had the best corrected pident.

Full Command (type in terminal):

Rscript calc_full_length_pident.R otus.custom.blast.table otus.custom.blast.table.modified


Separate all arguments with a space.

What each argument is:
	Rscript								sources the R script using the arguments supplied after it in the terminal.
	calc_full_length_pident.R			the R script.
	otus.custom.blast.table				the formatted blast output from step 3
	otus.custom.blast.table.modified	the output file containing the modified BLAST hit table, used in step 5.
										It contains tab delimited columns without column names. They are:
										qseqid, pident, length, qlen, q.align, true.pids, hit.num.best.ids

__________________________________________________________________________________________

5. filter BLAST results (R)

This R script, filter_seqIDs_by_pident.R, is run twice. First to generate the sequence ID's 
above/equal to the user specified "full length pident" cutoff.  Those sequence IDs are 
destined for taxonomy assignment in the small custom database.  Second it is run to generate 
the sequence ID's below the "full length pident" cutoff, which are destined for taxonomy 
assignment in the large general database.

Full Two Commands (type in terminal):

Rscript filter_seqIDs_by_pident.R otus.custom.blast.table.modified ids.above.98 98 TRUE 
Rscript filter_seqIDs_by_pident.R otus.custom.blast.table.modified ids.below.98 98 FALSE

What each argument is:
	Rscript								Sources the R script using the arguments supplied after it in the terminal.
	filter_seqIDs_by_pident.R			The R script.  
	otus.custom.blast.table.modified	the BLAST table with corrected, full length pident values created in step 4.
	ids.above.98 						the output file containing seqIDs at or above your cutoff value, used in step 7
	ids.below.98						the output file containing seqIDs below your cutoff value, used in step 7
										the format of these seqID output files are \n delimited seqIDs, no header.
	98									the full length pident cutoff you are using to decide which sequences belong
										in which taxonomy database classification
	TRUE								return seqID's >= cutoff
	FALSE								return seqID's < cutoff
	
__________________________________________________________________________________________

6. check that BLAST settings are appropriate (R)

There is no way to force BLAST to return only full-length hits, it will always return the 
best "High Scoring Pair (HSP)" it finds, based on it's scoring that weights both the quality
and length of the hit.  However, for this use we are only interested in full length matches
because the entire OTU sequences are matched to the reference 16S sequences when assigning 
taxonomy.

High pident short HSPs will be converted to low pident "full length" HSPs because all missing
basepairs are considered a mismatch by my conservative calculation in step 4.  Therefore, some high 
pident short HSPs are reported by BLAST instead of lower pident long HSPs. The true full length
pident could have been higher than my conservative calculation from the BLAST pident that assumes
all un-reported basepairs are mismatches.  If this is happening, then you might not include seqIDs
in your custom classification that met your cutoff.  However, the pident cutoff for taxonomy assignment 
using 16S sequences is pretty high, so while it's likely that some of the short BLAST HSPs
may have longer HSPs with better full-length pidents, it's less likely that any of those better, 
"true" pidents would be good enough to meet your pident criteria. 

The likelihood of incorrect results because of BLAST choosing HSPs that are not full length increases
as the length of your OTU sequences increases.  This step tries to check if this might
be a problem.  Generate some plots with the R script plot_blast_hit_stats.R.

Full Two Commands (type in the terminal)
mkdir plots
RScript plot_blast_hit_stats.R otus.custom.blast.table.modified 98 plots

What mkdir bash command does:
	mkdir		stands for "make directory", this creates a new folder
	plots		the name of the new folder you are creating
				this is where step 6 and step 14 will save plots generated for checking the cutoff

What each argument in the R script is:
	RScript								sources an R script and allows it to accept arguments from the command line
	plot_blast_hit_stats.R				the script you are sourcing
	otus.custom.blast.table.modified	the modified blast table produced in step 4.
	98									the pident cutoff you chose to filter your sequences by
	plots								the folder your generated plots will be saved in
	https://cran.mtu.edu				this is an OPTIONAL argument for those who
										1. don't have the "reshape" R package installed already
										2. live far away from the midwestern USA
										It's the web address to the cran mirror you use, choosing
										one close to you could make it slightly faster but
										this honestly doesn't matter much.  The script will automatically
										install the reshape package temporarily if you don't have it already   

What each generated file is:
	BLAST_hits_line_plot.png
	BLAST_hits_used_for_pident_98.png
	BLAST_hits_used_for_pidents_70-100.png
	BLAST_hits_used_for_pidents_90-100.png
	BLAST_hits_used_overall.png
	
****Choose which plots to keep*****
__________________________________________________________________________________________

7. recover sequence IDs left out of blast (python, bash)

Blast has a built in reporting cutoff based on evalue.  The blast expect value depends on
the length of the hit and the size of the database, and it reflects how frequently you 
would see a hit of that quality by chance. The default evalue cutoff is 10, which means 
blast does not report a match that you'd see 10 or more times by chance.  For more about
the evalue statistics, see: http://www.ncbi.nlm.nih.gov/BLAST/tutorial/Altschul-1.html

The python script find_seqIDs_blast_removed.py is used to find all of the 
sequence IDs in the original fasta file that do not appear in the blast output.  The python 
script then creates a new file in the same format as step 5's R script output file that
is a newline-delimited list of the missing sequence IDs.

The bash command cat concatenates these missing ids with the ids below the chosen cutoff
pident.  That is because the ids blast didn't report hits for had even worse pidents than 
the ones that didn't make the R script cutoff, so they belong in the set that will be 
classified by the general database.

Full Two Commands (type in terminal):

python find_seqIDs_blast_removed.py otus.fasta otus.custom.blast.table.modified ids.missing
cat ids.below.98 ids.missing > ids.below.98.all
						
What each argument is in python script:
	python							opens the python program to source the script
	find_seqIDs_blast_removed.py	python script you're sourcing
	otus.fasta						original fasta file of your sequences from step 0,
									this contains all the seqIDs
	otus.FW.blast.table.modified	reformatted blast results from step 4,
									this contains all the seqIDs reported by BLAST
	ids.missing						the output file of seqIDs that were left out of BLAST
									results.  Its format is new line delimited seqIDs, no header
	
What each argument in the bash script is:
	cat								function that concatenates two files
	ids.below.98					seqIDs below your cutoff from R script in step 5.
	ids.missing						seqIDs not returned by BLAST, from this step, above.
	> ids.below.98.all				combine those two files into this new one.
									this now contains all the seqIDs you will classify in
									the general taxonomy database, in \n delimited format.
									
__________________________________________________________________________________________

8. create fasta files of desired sequence IDs (python)

The create_fastas_given_seqIDs.py takes the sequence IDs selected using the blast output 
and finds them in the original query fasta file.  
It then creates a new fasta file containing just the desired sequences.
The script is run twice, first to create the fasta file for seqIDs above the pident cutoff,
second to create the fasta file for seqIDs below the pident cutoff.  The fasta files will 
be classified with the custom and general databases, respectively.

Full Two Commands (type in terminal):

python create_fastas_given_seqIDs.py ids.above.98 otus.fasta otus.above.98.fasta
python create_fastas_given_seqIDs.py ids.below.98.all otus.fasta otus.below.98.fasta

What each argument is:
	python							opens the python program to souce the script
	create_fastas_given_seqIDs.py	the python script you're sourcing 
	ids.above.98					the file of seqIDs at or above your cutoff from step 5
	ids.below.98.all				the file of all seqIDs below your cutoff from step 7
	otus.fasta						the original fasta file of all your OTU sequences from step 0
	otus.above.98.fasta				the output file with fasta sequences at or above your cutoff
	otus.below.98.fasta				the output file with fasta sequences below your cutoff
									NOTE: if this output file already exist the script will 
									delete it before starting.
	
__________________________________________________________________________________________

9. assign taxonomy (mothur)

The classify.seqs() command in mothur classifies sequences using a specified algorithm 
and a provided taxonomy database.  I use the default algorithm (wang with kmer size 8), 
and ask it to show bootstrap values. The output file is a list of sequence ID's next to
their assigned taxonomy.

Full Two Commands (type in terminal):

mothur "#classify.seqs(fasta=otus.above.98.fasta, template=custom.fasta,  taxonomy=custom.taxonomy, method=wang, probs=T, processors=2)"
mothur "#classify.seqs(fasta=otus.below.98.fasta, template=general.fasta, taxonomy=general.taxonomy, method=wang, probs=T, processors=2)"

What the first and last commands do:
	~/mothur/mothur		this is the path to the mothur program installed on your computer.
						~/mothur/mothur is the default place to instal it.
						You must open mothur to use the mothur command classify.seqs().
						When in the mothur program " mothur > " appears instead of $
	quit()				exits the mothur program and returns you back to bash in the terminal.

What the filenames are:
	otus.above.98.fasta		this is the fasta file containing only seqIDs >= your cutoff, from step 8
	otus.below.98.fasta		this is the fasta file containing only seqIDs < your cutoff, from step 8
	custom.fasta			this is the fasta file for your small custom taxonomy database (ie freshwater) 
	general.fasta			this is the fasta file for your large general taxonomy database (ie green genes) 
	custom.taxonomy			this is the .taxonomy file for your small custom taxonomy database (ie freshwater)
	general.taxonomy		this is the .taxonomy file for your large general taxonomy database (ie freshwater)

What each flag does:	
	fasta=		path to the .fasta file you want classified
	template=	path to the .fasta file of the taxonomy database
	taxonomy=	path to the taxonomy file of the taxonomy database
	method=		algorithm for assigning taxonomy. default is wang.
	probs=		T or F, show the bootstrap probabilities or not?
	cutoff=		minimum bootstrap value for getting a name instead of unclassified
				typically minimum is 60%
				note: the default is no cutoff, full reporting.  I have an R script that
				let's you apply a bootstrap cutoff after the fact if you want to see everything 1st
	processors=	the number of processors on your computer to run it on
				note: this did not work on my mac, still ran on only 1 core.

What the output files are (note you have no control over the name extensions added):
	otus.above.98.custom.wang.taxonomy
	otus.above.98.custom.wang.tax.summary
	otus.below.98.general.wang.taxonomy
	otus.below.98.general.wang.tax.summary

**** add in the database files that are generated too***
	
NOTE: these bootstrap percent confidence values are NOT the confidence that the taxonomy 
assignment is *correct*, just that it is *repeatable* in that database.  This is another 
paremeter that we could explore changing more in the future.  It likely should be different
in the different databases also because of the different database sizes.  I left cutoff out
in this command so that you can explore the different results of it later, in steps 13-14.


__________________________________________________________________________________________

10. combine taxonomy files (terminal)

Concatenate the two taxonomy files to create one complete one.  You can very simply just 
combine them because there are no duplicate sequences between them.  The cat command in bash
concatenates two files into one.  You also choose your final file name here.

Full Command (type in terminal):

cat otus.above.98.custom.wang.taxonomy otus.below.98.general.wang.taxonomy > otus.98.taxonomy

Command syntax:
	cat file1 file2 > file3		means "combine file1 and file2 into file 3"
								
What the filenames are:
	otus.above.98.custom.wang.taxonomy		the taxonomy file for sequences classified with custom database
	otus.below.98.general.wang.taxonomy		the taxonomy file for sequences classified with general database
	otus.taxonomy							the name you choose for the output complete taxonomy file for all
											your sequences.


__________________________________________________________________________________________

Steps 11-14 are an optional check.
__________________________________________________________________________________________

11. assign taxonomy with general database only (mothur, bash)

Get a large, general database classification of your otus.fasta file to compare too.  
Green Genes, our general database choice, is a huge database (1,262,986 sequences), so the 
taxonomy assignment clustering algorithm is likely to only settle on a given taxonomic 
assignment if it is unambiguously correct.  Therefore, we trust the upper level Green Genes
assignments more than our custom database, even though we trust the lower level taxonomic
assignments using our custom database more.

So in this step you assign taxonomy with the general database using mothur, and then
rename the output file something easy to work with using bash.

Full Two Commands (type in terminal):

mothur "#classify.seqs(fasta=otus.fasta, template=general.fasta, taxonomy=general.taxonomy, method=wang, probs=T, processors=2)"
cat otus.general.wang.taxonomy > otus.general.taxonomy

What the commands do:
	See step 9 for a detailed explanation of these two commands and their arguments.

What the filenames are:
	otus.fasta					the original fasta file of your OTU sequences
	general.fasta				the fasta file of the large, general database
	general.taxonomy			the taxonomy file of the large, general database
	otus.general.wang.taxonomy	the taxonomy of your OTUs assigned by the general database
								this is the default name created by mothur
	otus.general.taxonomy		the otus.general.wang.taxonomy file renamed


__________________________________________________________________________________________

11.5 assign taxonomy to custom database with general database (mothur, bash)

This allows you to compare your two databases to get an idea of the baseline level of 
disagreement you can expect from their taxonomy classifications.  Also, in step 13 you
will generate a list of these disagreements that you can use to update your custom
database classifications to better match your general database, if desired.  When you 
choose an appropriate pident cutoff the goal is to avoid forcing OTUs into the custom
database, which can be seen when the general database gives a very different 
classification. Knowing the level of disagreement between the databases themselves can
give you an idea of how much disagreement is acceptable.

Full Two Commands (Type in Terminal):

mothur "#classify.seqs(fasta=custom.fasta, template=general.fasta, taxonomy=general.taxonomy, method=wang, probs=T, processors=2)"
cat custom.general.wang.taxonomy custom.general.taxonomy


What the commands do:
	See step 9 for a detailed explanation of these two commands and their arguments.

What the filenames are:
	custom.fasta					the fasta file of the small, custom database
	general.fasta					the fasta file of the large, general database
	custom.general.wang.taxonomy	the taxonomy of your custom database assigned by the general database
									this is the default name created by mothur
	custom.general.taxonomy			the custom.general.wang.taxonomy file renamed
	
	
__________________________________________________________________________________________

12. reformat taxonomy files (bash)

The R script in step 13 requires semicolon delimited taxonomy files.  The mothur output
.taxonomy files are delimited with both tabs and semicolons.

Reformat both files you will compare:
	the otus.taxonomy file created in step 10
	the otus.general.taxonomy file created in step 11

Find: tab
Replace: semicolon

Full Seven Commands (Type in Terminal):

sed 's/[[:blank:]]/\;/' <otus.98.taxonomy >otus.98.taxonomy.reformatted
mv otus.98.taxonomy.reformatted otus.98.taxonomy
sed 's/[[:blank:]]/\;/' <otus.general.taxonomy >otus.general.taxonomy.reformatted
mv otus.general.taxonomy.reformatted otus.general.taxonomy


Syntax of commands and what each argument does:
	sed 's/find/replace/ <input >output
		sed		is a "stream editor," a function for editing streams of text in the terminal
		's		tells it you are doing a substitution
		find	this is the character string you are finding
		replace	this is what you are replacing it with
		input	this is the file sed searches through, here it is
				otus.taxonomy
				otus.general.taxonomy
		output	this is the file sed creates (note it must have a different name than input)
	
	mv filename1 filename2
		mv		this is a function to move (aka rename) a file from name1 to name2
				simply keeping the edited file the same name  
		

__________________________________________________________________________________________

13. compare taxonomy files (bash, R)

The R script find_classification_disagreements.R  creates a folder containing a file for 
each upper taxonomic level (kingdom, phylum, class, order, lineage) that lists all of the 
classification disagreements at that taxonomic level between the custom + general taxonomy
database workflow and the general only taxonomy database workflow. Note that this only 
compares classifications made in the custom database, it ignores differences between 
classifications that were both made by the general database (which can happen because 
the classification algorithm is stochastic.)

This script also allows the user to choose a bootstrap %confidence cutoff under which all
the lower assignments are unclassified.  The script does not include unclassified names in 
its reporting of disagreements.  This allows you ignore taxonomy assignment conflicts when
you don't trust the assignment anyway, and you can decide what you trust (60% is generally
considered the minimum cutoff you should use.)

Additionally, this script generates a final version of your taxonomy file with the applied 
bootstrap cutoff implemented.  The version made in step 9 contains all the taxonomy assignments,
even ones with very low bootstrap p-values.  This generates a .taxonomy file with the cutoff
applied, so that everything under that cutoff is named "unclassified."  Note that you can 
apply this cutoff in step 9 using the "cutoff = #" flag with the mothur command classify.seqs().
I didn't do it there though to make these analysis steps more flexible. The format of this file
is semicolon delimited, which is slightly different than the mothur output files that are tab 
semicolon deliminited between taxonomy levels but tab delimited between the seqID column and
the taxonomy names.

Note: you must create a new folder to save these results in before running the script.
	include the pident cutoff in your folder name, b/c the file names will not include that.
	(Suggested folder name and creation is below.)

Full Two Commands (type in terminal):

mkdir conflicts_98
Rscript find_classification_disagreements.R otus.98.taxonomy otus.general.taxonomy ids.above.98 conflicts_98 98 85 70

Note: you must enter all the arguments in this order.

What the arguments are the first time you source the script:
1.	Rscript									this opens R to accept arguments from the command line
2.	find_classification_disagreements.R		this is the R script you're sourcing
3.	otus.98.taxonomy						this is the path to your otu taxonomy file 
											created using both databases in step 10
4.	otus.general.taxonomy					this is the path to your otu taxonomy file
											created using only the general database in step 11
5.	ids.above.98							this is the path to the file created in step 4 that
											contains all of the sequence IDs above or equal to 
											your pident cutoff
6.	conflicts_98							this is the path to the folder you want the R script
											to save the .csv results files in. You create this
											folder in this step with the mkdir command.
7.	98										this is the pident you're using.
8.	85										this is the p-value cutoff for the custom database
											assigned sequences. This determines if a classification
											is good enough to be named or should be "unclassified." 
9.	70										this is the p-value cutoff for the general database
											assigned sequences. This determines if a classification
											is good enough to be named or should be "unclassified." 
	
What the arguments are the second time you source the script:
1.	Rscript									this opens R to accept arguments from the command line
2.	find_classification_disagreements.R		this is the R script you're sourcing
3.	custom.custom.taxonomy					this is the path to your custom taxonomy database 
											after re-formatting it in step 12.
4.	custom.general.taxonomy					this is the path to your custom taxonomy database
											classified using the general database in step 11.
5.	NA										NA is typed as a placeholder here
6.	conflicts_database						this is the path to the folder you want the R script
											to save the .csv results files in. You create this
											folder in this step with the mkdir command.
7.	NA										NA is typed as a placeholder here
8.	NA										NA is typed as a placeholder here
9.	70										this is the p-value cutoff for the general database
											assignments of the custom database fastas. This 
											determines if a classification is good enough to be
											named or should be "unclassified." 	
10.	database								This flag tells the script you are comparing two
											databases instead of OTU classifications.

What the generated files in your conflicts folders are:
	kingdom_conflicts.csv
	phylum_conflicts.csv
	class_conflicts.csv
	order_conflicts.csv
	lineage_conflicts.csv
	conflicts_summary.csv


__________________________________________________________________________________________

14. choose appropriate pident cutoff (R)

This step generates some plots that you can use to double check that your chosen cutoff is 
appropriate.  The plots are saved into the "plots" folder that you created in step 6.  In
order to examine the cutoff sensitivity, you may want to run steps 4-10 & 12-13 multiple times
with different pident cutoffs.  Note that the slowest step, classify.seqs() in mothur, will
be much faster because the mothur database files are not re-made.

Rscript plot_classification_disagreements.R otus.abund plots regular regular conflicts_94 ids.above.94 94 conflicts_96 ids.above.96 96 conflicts_98 ids.above.98 98

What the arguments are:
1.		Rscript									Calls program R in a way that accepts command line arguments
2.		plot_classification_disagreements.R		name of the script you are calling
3.		otus.abund								OTU relative abundance table
4.		plots									path to folder you are saving the plots into.
												note: this folder must already exist. you made it in step 6.
5.		conflicts_database						path to folder containing taxonomy disagreements between
												the custom and the general database.
												You made this folder in step 12.
6.		regular									placeholder, this is only used in the step where you plot forcing
7.		regular									also placeholder. Note: these must say "regular" though.
6.		conflicts_94							path to folder containing taxonomy disagreements between
												this cutom+general workflow and the general database alone.
												You made this folder in step 13.
7.		ids.above.94							path to the file that lists all the seqIDs meeting your
												pident cutoff that were therefore classified with your
												custom databse. You made this file in step 4.
8.		94										pident cutoff used in the previous two arguments
8.		conflicts_96							folder of taxonomy disagreements
9.		ids.above.96							file of custom-classified seqIDs	
10.		96										pident cutoff for previous two arguments
n.		...										additional arguments
												you can have as many pident cutoffs compared as you
												want.  Just keep listing them in this format:
												folder_path ids.file pident folder_path ids.file pident ...

What the generated plots are:
	***choose which ones to export***

__________________________________________________________________________________________

15. generate final taxonomy file (R)

Based on your results from step 14, choose which pident cutoff to use.  Use the same script 
from step 13, except this time specify "final."  This final taxonomy file is different from 
files created in step 9 because it applies your clustering bootstrap pvalue cutoff, calling
everything below that cutoff "unclassified."  

Recall that choosing that cutoff was left out of the mothur command to allow flexibility in
analyzing results.  The "final" argument to this script is left out in step 13 because it takes
longer when it is included.  This is because in finding the classification disagreements, the
script only compares classifications assigned by the custom database, which is a small subset 
of all of the classifications.

Rscript find_classification_disagreements.R otus.98.taxonomy otus.general.taxonomy ids.above.98 conflicts_98 98 85 70 final

What the arguments are this (3rd) time you source the script:
1.	Rscript									this opens R to accept arguments from the command line
2.	find_classification_disagreements.R		this is the R script you're sourcing
3.	otus.98.taxonomy						this is the path to your otu taxonomy file 
											created using both databases in step 10
4.	otus.general.taxonomy					this is the path to your otu taxonomy file
											created using only the general database in step 11
5.	ids.above.98							this is the path to the file created in step 4 that
											contains all of the sequence IDs above or equal to 
											your pident cutoff
6.	conflicts_98							this is the path to the folder you want the R script
											to save the .csv results files in. You create this
											folder in this step with the mkdir command.
7.	98										this is the pident you're using.
8.	85										this is the p-value cutoff for the custom database
											assigned sequences. This determines if a classification
											is good enough to be named or should be "unclassified." 
9.	70										this is the p-value cutoff for the general database
											assigned sequences. This determines if a classification
											is good enough to be named or should be "unclassified." 
10.	final									this flag lets the script know you want a final file generated.
											therefore it applies the bootstrap p-value cutoff to the
											entire script instead of just the custom-classified seqIDs.
											That's why it will take longer this time you run the script.


__________________________________________________________________________________________

15.5 OPTIONAL: plot benefits of using this workflow (R)

15.5.a. Plot improvement over using general database alone

In this step two plots are generated that show you the benefit of using the custom workflow.
The plots show the number of known taxonomic assignments by either % of total OTUs or % of 
total reads.  Basically, the script sums up everything that is not called "unclassified"
in the final workflow taxonomy file and the general database taxonomy file with the bootstrap
p-value cutoffs applied.  These files are both generated in step 15.

Full Command (Type into terminal):

Rscript plot_classification_improvement.R final.taxonomy.pvalues final.general.pvalues total.reads.per.seqID.csv plots

What the arguments are:
	final.taxonomy.pvalues			a file of p-values corresponding to the final taxonomy file you
									generated in step 15.  This file, with this name, was automatically
									generated in step 15 so it is already in your working directory.
	final.general.pvalues 			a file of p-values corresponding to the general-classified taxonomy
									after the classification p-value cutoff has been applied. This file,
									with this name, was automatically generated in step 15 so it is already
									in your working directory.
	total.reads.per.seqID			a file that lists each seqID and the total number of reads for that
									seqID.  This file, with this name, was automatically generated in
									step 13, using your otus.abund table, so it is already in your 
									working directory.
	plots							the name of the folder that plots are saved into.  you created this
									folder in step 6.

15.5.b. Plot folly of using custom database alone

In this step the classifications you get using the custom database alone are compared to the final workflow
taxonomy file generated in step 15.  The plots created show the "forcing" that would occur from using only
the small database.  Forcing occurs because the RDP classifier classifies sequences stochastically, putting
them with the most similar sequence *in your database*.  If there are no similar sequences and the database is 
large, then the sequence will be put somewhere different each time, end up with a low p-value, and be called
unclassified.  However in a smaller database, it's possible that a dissimilar sequence might be put reliably
in the same classification because it is most similar to that, even though the sequence itself is very dissimilar.
This is what I call forcing.  These plots take longer to generate because first you must classify your OTUs 
with the custom database alone, and then you must group the classifications by taxonomic level (all other
steps in this workflow are on an OTU-level.) However, the plots are very beautiful so it is worth your wait. :)

mothur "#classify.seqs(fasta=otus.fasta, template=custom.fasta, taxonomy=custom.taxonomy, method=wang, probs=T, processors=2)"
cat otus.custom.wang.taxonomy > otus.custom.taxonomy

sed 's/[[:blank:]]/\;/' <otus.custom.taxonomy >otus.custom.taxonomy.reformatted
mv otus.custom.taxonomy.reformatted otus.custom.taxonomy

mkdir conflicts_forcing
Rscript find_classification_disagreements.R otus.custom.taxonomy otus.98.85.70.taxonomy ids.above.98 conflicts_forcing NA 85 70 forcing

Rscript plot_classification_disagreements.R otus.abund plots NA conflicts_forcing otus.custom.85.taxonomy NA NA
									
__________________________________________________________________________________________

16. tidy up (bash)

This step tidies up your working directory folder by removing intermediate files you don't 
need anymore and moving remaining files into orgainized folders.
Note: these bash commands only work if you've been using the same names as the workflow.
Note: go through these commands in order.


16.1 remove intermediate files

Full Command (Type in Terminal):

rm custom.db.* custom.8mer custom.custom* custom.tree* general.8mer general.general* general.tree* *wang* mothur.*.logfile otus.custom.blast* ids* otus.below*.fasta otus.above*.fasta otus.[0-9][0-9].taxonomy otus.[0-9][0-9][0-9].taxonomy otus.general.taxonomy otus.custom.taxonomy custom.general* otus.custom.[0-9]* *pvalues total*

What each of these intermediate files is and why you might want to keep them:
custom.db.*		The blast database files (saves time if you want to re-run blast on the same taxonomy database)
custom.8mer custom.custom* custom.tree* general.8mer general.general* general.tree*
				The mothur database files (saves time if you want to re-run classify seqs with the same taxonomy database)
				This also removes custom.custom.taxonomy, which was only for comparison and isn't needed anymore either
*wang* mothur.*.logfile
				The mothur classify seqs output files (these can be regenerated relatively quickly if you save mothur db files)
otus.custom.blast*
				The blast results (these are quick to regenerate if you have the blast database)
ids*			lists of seqIDs (not needed once you have the fasta files)
otus.below*.fasta otus.above*.fasta
				separated fasta files from the custom & general classifications (not needed post-classification.)
otus.[0-9][0-9].taxonomy otus.[0-9][0-9][0-9].taxonomy otus.general.taxonomy otus.custom.taxonomy otus.custom.[0-9]* custom.general*
				the classifications at different pident cutoffs and from general and custom alone and the database comparison
				note: these files don't have p-value cutoffs applied (i.e. nothing's called unclassified). 
				If you want to save files like these for additional analysis, 
					re-run step 15 to get additional "final" versions.
					re-run step 11 with an additional "cutoff=" flag.
*pvalues total*	These are files generated to use in the plot improvement script


Note: if for some reason you want to keep these files, you can either skip this step
or type in the terminal:

mkdir intermediate
mv custom.db.* custom.8mer custom.custom* custom.tree* general.8mer general.general* general.tree* *wang* mothur.*.logfile otus.custom.blast* ids* otus.below*.fasta otus.above*.fasta otus.[0-9][0-9].taxonomy otus.[0-9][0-9][0-9].taxonomy *.general.taxonomy intermediate/


16.2 move scripts into scripts folder

Full 2 commands (Type in Terminal):

mkdir scripts
mv *.py *.R *.sh scripts/

Note: I recommend saving all the script versions you used to create your data so you could reproduce it.


16.3 save files used in analyzing your results in analysis folder

Full 2 commands (Type in Terminal):

mkdir analysis/
mv conflicts* plots/ analysis/

Note: You can delete this instead if you're all done analyzing. Instead of the two commands, type:

rm -r conflicts* plots/

16.4 save your actual data files in a folder called data

Full Two commands (Type in Terminal):

mkdir data
mv otus* data/

Note: Yeyy!  This is what you're gonna use to actually do stuff now!!


16.5 save the version of the taxonomy databases you used in a databases folder

Full Two Commands (type in terminal):

mkdir databases
mv *.taxonomy *.fasta databases

Note: I highly recommend you keep these versions of the databases you used so you can reproduce your data.


__________________________________________________________________________________________

~The end~
__________________________________________________________________________________________